# -*- coding: utf-8 -*-
"""530 Evaluation Script

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WkmralQ8Iu8hTga6VNcKQsgxFanyCU63

# Evaluation Metrics: Accuracy, Precision, Recall, and F-score
"""

## Input: y_pred, a list of length n with the predicted labels,
## y_true, a list of length n with the true labels

## Calculates the accuracy of the predicted labels
def get_accuracy(y_pred, y_true):
    C = 0
    I = 0
    for i in range(len(y_pred)):
        pred = y_pred[i]
        true = y_true[i]
        if pred == true:
            C += 1
        else:
            I += 1
    if(C == 0):
        return 0
    accuracy = C/(C + I)
    return accuracy


## Calculates the precision of the predicted labels
def get_precision(y_pred, y_true):
    TP = 0
    FP = 0
    for i in range(len(y_pred)):
        pred = y_pred[i]
        true = y_true[i]
        if pred == 1 and true == 1:
            TP += 1
        if pred == 1 and true == 0:
            FP += 1
    if(TP == 0):
        return 0
    precision = TP/(FP + TP)
    return precision

## Calculates the recall of the predicted labels
def get_recall(y_pred, y_true):
    TP = 0
    FN = 0
    for i in range(len(y_pred)):
        pred = y_pred[i]
        true = y_true[i]
        if pred == 1 and true == 1:
            TP += 1
        if pred == 0 and true == 1:
            FN += 1
    if(TP == 0):
        return 0
    recall = TP/(FN + TP)
    return recall

## Calculates the f1 score of the predicted labels
def get_fscore(y_pred, y_true):
    recall = get_recall(y_pred, y_true)
    precision = get_precision(y_pred, y_true)
    fscore = 2*(recall * precision)/(recall + precision)
    return fscore

## Function to calculate and print all the evaluation metrics
def test_predictions(y_pred, y_true):
    accuracy = get_accuracy(y_pred, y_true)
    recall = get_recall(y_pred, y_true)
    precision = get_precision(y_pred, y_true)
    fscore = get_fscore(y_pred, y_true)
    print("Accuracy: " + str(accuracy) + "\n")
    print("Recall: " + str(recall) + "\n")
    print("Precision: " + str(precision) + "\n")
    print("Fscore: " + str(fscore) + "\n")

## Example Output
A = [1, 0, 1, 1, 1, 1, 0, 1, 0, 0]
B = [1, 1, 0, 1, 1, 0, 0, 1, 0, 0]
test_predictions(A, B)